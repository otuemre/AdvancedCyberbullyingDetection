{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "086e2f7b-55f5-4714-9dff-4e2fc9f1ed5a",
   "metadata": {},
   "source": [
    "# Advanced Cyberbullying Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5b3759-40e1-4693-932a-59ead8eb4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Seed\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49abf2a4-ebe0-4014-b87e-8f687c838a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "# GPU Availability\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2a556-0b35-4cc3-80a2-ff0504c6e0a1",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e47c599-4eae-4d29-8d43-7f3c11a8762c",
   "metadata": {},
   "source": [
    "**Load Dataset**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e7366d9-7d5f-430a-af2d-6b70805a259d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSVs: 9\n",
      "aggression_parsed_dataset.csv\n",
      "attack_parsed_dataset.csv\n",
      "cyberbullying_tweets.csv\n",
      "kaggle_parsed_dataset.csv\n",
      "toxicity_parsed_dataset.csv\n",
      "twitter_parsed_dataset.csv\n",
      "twitter_racism_parsed_dataset.csv\n",
      "twitter_sexism_parsed_dataset.csv\n",
      "youtube_parsed_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../dataset\")\n",
    "\n",
    "# Check available datasets\n",
    "csv_paths = sorted(DATA_DIR.glob(\"*.csv\"))\n",
    "\n",
    "print(\"Found CSVs:\", len(csv_paths))\n",
    "for f in csv_paths:\n",
    "    print(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1d3ba2b-f5a6-4237-b99a-2bceabac2dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\dataset\\aggression_parsed_dataset.csv: shape=(115864, 5)\n",
      "..\\dataset\\attack_parsed_dataset.csv: shape=(115864, 5)\n",
      "..\\dataset\\cyberbullying_tweets.csv: shape=(47692, 2)\n",
      "..\\dataset\\kaggle_parsed_dataset.csv: shape=(8799, 4)\n",
      "..\\dataset\\toxicity_parsed_dataset.csv: shape=(159686, 5)\n",
      "..\\dataset\\twitter_parsed_dataset.csv: shape=(16851, 5)\n",
      "..\\dataset\\twitter_racism_parsed_dataset.csv: shape=(13471, 5)\n",
      "..\\dataset\\twitter_sexism_parsed_dataset.csv: shape=(14881, 5)\n",
      "..\\dataset\\youtube_parsed_dataset.csv: shape=(3464, 10)\n"
     ]
    }
   ],
   "source": [
    "# Read dfs\n",
    "dfs = {}\n",
    "\n",
    "for f in csv_paths:\n",
    "    path = DATA_DIR / f\n",
    "    dfs[f] = pd.read_csv(path)\n",
    "    print(f\"{f}: shape={dfs[f].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fb441b0-9a22-48d1-8ea3-2f87df9ea765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\dataset\\aggression_parsed_dataset.csv, Columns: Index(['index', 'Text', 'ed_label_0', 'ed_label_1', 'oh_label'], dtype='str')\n",
      "..\\dataset\\attack_parsed_dataset.csv, Columns: Index(['index', 'Text', 'ed_label_0', 'ed_label_1', 'oh_label'], dtype='str')\n",
      "..\\dataset\\cyberbullying_tweets.csv, Columns: Index(['tweet_text', 'cyberbullying_type'], dtype='str')\n",
      "..\\dataset\\kaggle_parsed_dataset.csv, Columns: Index(['index', 'oh_label', 'Date', 'Text'], dtype='str')\n",
      "..\\dataset\\toxicity_parsed_dataset.csv, Columns: Index(['index', 'Text', 'ed_label_0', 'ed_label_1', 'oh_label'], dtype='str')\n",
      "..\\dataset\\twitter_parsed_dataset.csv, Columns: Index(['index', 'id', 'Text', 'Annotation', 'oh_label'], dtype='str')\n",
      "..\\dataset\\twitter_racism_parsed_dataset.csv, Columns: Index(['index', 'id', 'Text', 'Annotation', 'oh_label'], dtype='str')\n",
      "..\\dataset\\twitter_sexism_parsed_dataset.csv, Columns: Index(['index', 'id', 'Text', 'Annotation', 'oh_label'], dtype='str')\n",
      "..\\dataset\\youtube_parsed_dataset.csv, Columns: Index(['index', 'UserIndex', 'Text', 'Number of Comments',\n",
      "       'Number of Subscribers', 'Membership Duration', 'Number of Uploads',\n",
      "       'Profanity in UserID', 'Age', 'oh_label'],\n",
      "      dtype='str')\n"
     ]
    }
   ],
   "source": [
    "# Check Columns\n",
    "for fname, df in dfs.items():\n",
    "    print(f\"{fname}, Columns: {df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b9c02-fdc8-40a3-9b53-5bcef8441075",
   "metadata": {},
   "source": [
    "**Clean Dataset**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d411bb46-142d-49e8-96d3-3d07dce0084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unwanted columns and rename the column names\n",
    "cleaned_dfs = {}\n",
    "\n",
    "for fname, df in dfs.items():\n",
    "    # Get the text column\n",
    "    if \"tweet_text\" in df.columns:\n",
    "        text_col = \"tweet_text\"\n",
    "    else:\n",
    "        text_col = \"Text\"\n",
    "\n",
    "    # Get the label column\n",
    "    if \"cyberbullying_type\" in df.columns:\n",
    "        label_col = \"cyberbullying_type\"\n",
    "    else:\n",
    "        label_col = \"oh_label\"\n",
    "\n",
    "    # Keep the columns and rename\n",
    "    out = df[[text_col, label_col]].copy()\n",
    "    out = out.rename(columns={text_col: \"text\", label_col: \"is_cyberbullying\"})\n",
    "\n",
    "    # Assign the cleaned dfs\n",
    "    cleaned_dfs[fname] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4cae363-9175-44aa-a1ac-230337510264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\dataset\\aggression_parsed_dataset.csv, Columns: Index(['text', 'is_cyberbullying'], dtype='str')\n",
      "..\\dataset\\attack_parsed_dataset.csv, Columns: Index(['text', 'is_cyberbullying'], dtype='str')\n",
      "..\\dataset\\cyberbullying_tweets.csv, Columns: Index(['text', 'is_cyberbullying'], dtype='str')\n",
      "..\\dataset\\kaggle_parsed_dataset.csv, Columns: Index(['text', 'is_cyberbullying'], dtype='str')\n",
      "..\\dataset\\toxicity_parsed_dataset.csv, Columns: Index(['text', 'is_cyberbullying'], dtype='str')\n",
      "..\\dataset\\twitter_parsed_dataset.csv, Columns: Index(['text', 'is_cyberbullying'], dtype='str')\n",
      "..\\dataset\\twitter_racism_parsed_dataset.csv, Columns: Index(['text', 'is_cyberbullying'], dtype='str')\n",
      "..\\dataset\\twitter_sexism_parsed_dataset.csv, Columns: Index(['text', 'is_cyberbullying'], dtype='str')\n",
      "..\\dataset\\youtube_parsed_dataset.csv, Columns: Index(['text', 'is_cyberbullying'], dtype='str')\n"
     ]
    }
   ],
   "source": [
    "# Check Columns\n",
    "for fname, df in cleaned_dfs.items():\n",
    "    print(f\"{fname}, Columns: {df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f25dd8-aa1a-4860-8549-95cc559b0c30",
   "metadata": {},
   "source": [
    "**Combine Dfs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a24b899d-efa3-4fde-bbab-99b0bcd28684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Shape: (496572, 2)\n"
     ]
    }
   ],
   "source": [
    "# Combine all\n",
    "df = pd.concat(cleaned_dfs.values(), ignore_index=True)\n",
    "\n",
    "print(\"DF Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ac97483-9a5b-4d25-9b4d-b0becc8379fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_cyberbullying</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>`- This is not ``creative``.&nbsp;&nbsp;Those are the di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>`&nbsp;&nbsp;:: the term ``standard model`` is itself le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True or false, the situation as of March 200...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text is_cyberbullying\n",
       "0  `- This is not ``creative``.  Those are the di...                0\n",
       "1  `  :: the term ``standard model`` is itself le...                0\n",
       "2    True or false, the situation as of March 200...                0\n",
       "3   Next, maybe you could work on being less cond...                0\n",
       "4               This page will need disambiguation.                 0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738874e-0883-466e-91e2-8ac252de01de",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdc7d77f-994f-41dc-952f-f58c2bde16a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 'not_cyberbullying', 'gender', 'religion',\n",
       "       'other_cyberbullying', 'age', 'ethnicity', nan], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values in label\n",
    "df['is_cyberbullying'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a7ee2c0-644c-426e-8a01-ab8eb2553431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Values\n",
    "cyberbullying = [1, 'gender', 'religion', 'other_cyberbullying', 'age', 'ethnicity']\n",
    "not_cyberbullying = [0, 'not_cyberbullying']\n",
    "\n",
    "# Conditions\n",
    "def convert_binary(label):\n",
    "    # Check if in cyberbullying\n",
    "    if label in cyberbullying:\n",
    "        return 1\n",
    "\n",
    "    # Check if in not_cyberbullying\n",
    "    if label in not_cyberbullying:\n",
    "        return 0\n",
    "\n",
    "    # NaN case\n",
    "    return None\n",
    "\n",
    "df['is_cyberbullying'] = df['is_cyberbullying'].apply(convert_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c355c9fd-f3ab-4068-a4c6-791b2744dca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., nan])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values in label\n",
    "df['is_cyberbullying'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7198df3f-b965-479b-8eab-d05a2b350d4a",
   "metadata": {},
   "source": [
    "**Drop NaN Values**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7135e56-c862-4afb-9de1-1895cd7a5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"is_cyberbullying\"]).reset_index(drop=True)\n",
    "df[\"is_cyberbullying\"] = df[\"is_cyberbullying\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82bc3046-0ee3-41dd-baf1-4ace8ac8d245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_cyberbullying\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c794717-2d69-467e-9b10-0054fe85abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing text: 0\n",
      "Missing labels: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing text:\", df[\"text\"].isna().sum())\n",
    "print(\"Missing labels:\", df[\"is_cyberbullying\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fc33c86-c87f-457f-b951-6b43002e0b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_cyberbullying\n",
       "0    0.803857\n",
       "1    0.196143\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of the label\n",
    "df[\"is_cyberbullying\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ced61d-0b1a-45ff-a702-143747bc72bb",
   "metadata": {},
   "source": [
    "## Explatory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8e0db-3733-484c-8fb0-6dc9e0d86c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
